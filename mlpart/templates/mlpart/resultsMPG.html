<!DOCTYPE html>
<html lang="en">
<head>
    {% load static %}
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>GV AI EXPLAINABILITY</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
    <link rel="shortcut icon" href="{% static 'pages/Artificial-Intelligence-Trends.jpeg' %}"/>
    <style>
        .bs-example {
            margin: 20px;
        }

        .imgbox {
            display: grid;
            height: 100%;
        }

        .center-fit {
            max-width: 100%;
            max-height: 100vh;
            margin: auto;
        }
    </style>
</head>

<body>

<nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"></nav>

<main role="main">

    <div style="padding: 50px 0px 5px!important" class="jumbotron">
        <div class="container">
            <div class="row justify-content-start">

                <div class="col">
                    <h5 class="text-success display-4">The MPG score is {{scoreval}}
                        <input type="hidden" name="mpgVal" value={{scoreval}}>
                    </h5>
                </div>

                <div style="padding: 15px 0px 10px!important" class="d-flex justify-content-end">
                    <div class="col-md">
                        <h5>Want to make another mpg prediction?</h5>
                        <p><a style="width: 360px !important;" class="btn btn-secondary text-info"
                              href="/mlpart/mpg/" role="button">Go Ahead »</a></p>
                    </div>
                </div>

            </div>
        </div>
    </div>

    <div class="container">
        <h5>
            <p>But you may be wondering, how did we come to that outcome? We used a Random Forest Regression model to
                make the prediction, that was trained
                with the following dataset: <a href="https://archive.ics.uci.edu/ml/datasets/auto+mpg">Auto MPG Data
                    Set</a>.
                To explain the model both globally and locally, we will use the fast TreeExplainer in SHAP.
                The plots you are about to see, were made using the random data (320 observations) that were used to
                train the model.</p>
            <br><br>
            <p>&rarr;Firstly we will explain the entire dataset through the visualization of the importance of the
                features and
                their impact on the prediction. For that we will use the <i>'Variance Importance'</i> and <i>'Summary'
                    plots</i>.</p>
        </h5>
        <br>

        <div class="container" align="center">
            <div class="row justify-content-start">

                <div class="container">
                    <h4>&check;Explaining the entire dataset:</h4>
                    <br>
                    <div class="tab">
                        <button class="tablinks" onclick="openCity(event, 'Variable Importance Plot ')"
                                id="defaultOpen">Variable Importance Plot
                        </button>
                        <button class="tablinks" onclick="openCity(event, 'Summary Plot')">Summary Plot</button>
                    </div>

                    <br>
                </div>

                <div id="Variable Importance Plot " class="tabcontent">
                    <h6><p> The variable importance plot lists the most significant variables in descending order. The top
                    variables contribute more to the model than the bottom ones and thus have high predictive power. So in this case
                    "Displacement" and "Model Year" contribute more to the predicted outcome, when "Acceleration" does
                    not seem to change the choice of the model in any significant way.</p></h6>
                    <img src="{% static 'mlpart/MpgSPbarGlobaldata.jpeg' %}"/>
                </div>

                <div id="Summary Plot" class="tabcontent">
                    <h6><p> Another option to explain our model globally is the "Summary Plot" and it works as follows:<br>
                    &rarr;Feature importance: Variables are ranked in descending order.<br>
                    &rarr;Impact: The horizontal location shows whether the effect of that value is associated with a higher
                    or lower prediction.<br>
                    &rarr;Original value: Color shows whether that variable is high (in red) or low (in blue) for that
                    observation.<br>
                    &rarr;Correlation: A high level of the “Model Year” content has a high and positive impact on the
                    prediction. The “high” comes from the red color,
                    and the “positive” impact is shown on the X-axis. Similarly, we will say the “Displacement” is
                    negatively correlated with the target variable. </p></h6>
                    <img src="{% static 'mlpart/MpgSPGlobaldata.jpeg' %}"/>
                </div>

            </div>
            <br>


        </div>

    </div>


    <br>


    <div class="container">
        <h5>
            <p>&rarr;Secondly, we will focus on explaining single features by plotting the SHAP value of that feature vs. the
            value of the feature for all instances in the dataset. We will do that by plotting <i>Partial Dependence Plots</i>.
            The partial dependence plot shows the marginal effect one or two features have on the predicted outcome of a
            machine learning model.The function automatically includes another variable that your chosen variable
                interacts most with.</p>
        </h5>
        <br>

        <div class="container" align="center">
            <div class="row justify-content-start">

                <div class="container">
                    <h4>&check;Explaining single feature:</h4>
                    <br>
                    <div class="tab">
                        <button class="tablinks" onclick="openCity(event, 'Cylinders')" id="defaultOpen1">
                            Cylinders
                        </button>
                        <button class="tablinks" onclick="openCity(event, 'Displacement')">Displacement</button>
                        <button class="tablinks" onclick="openCity(event, 'Horsepower')">Horsepower</button>
                        <button class="tablinks" onclick="openCity(event, 'Weight')">Weight</button>
                        <button class="tablinks" onclick="openCity(event, 'Acceleration')">Acceleration</button>
                        <button class="tablinks" onclick="openCity(event, 'ModelY')">Model Year</button>
                    </div>
                    <br>
                </div>

                <div id="Cylinders" class="tabcontent">
                    <h6><p>The plot below shows there exists a negative relationship between
                    “Cylinders” and the target variable. The more the cylinders the lower the mpg of the vehicle will
                    be. Also the interaction between "Cylinders" and "Weight" appears sparse.</p></h6><br>
                    <img src="{% static 'mlpart/MpgDPCylindersdata.jpeg' %}"/>
                </div>

                <div id="Displacement" class="tabcontent">
                    <h6><p>The following plot shows there is an approximately linear and negative trend between “Displacement”
                    and
                    the target variable. The higher the displacement the lower the predicted value will be. Also
                    “Displacement” interacts with “Model Year” frequently.</p></h6><br>
                    <img src="{% static 'mlpart/MpgDPDisplacementdata.jpeg' %}"/>
                </div>

                <div id="Horsepower" class="tabcontent">
                    <h6><p>The following plot shows there is a linear and negative trend between “Horsepower” and
                    the target variable. When a vehicle possess a lot of horsepower, the mpg will be lower.
                    According to the graph "Horsepower" interacts with “Displacement” frequently.</p></h6><br>
                    <img src="{% static 'mlpart/MpgDPHorsepowerdata.jpeg' %}"/>
                </div>

                <div id="Weight" class="tabcontent">
                    <h6><p>The plot below shows there exists an approximately linear and negative relationship between “Weight"
                    of the vehicle and the target variable,which means that a heavier car will do less miles per gallon compared to a lighter one.</p></h6><br>
                    <img src="{% static 'mlpart/MpgDPWeightdata.jpeg' %}"/>
                </div>

                <div id="Acceleration" class="tabcontent">
                    <h6><p>When it comes to "Acceleration", we can see from the graph that there is a complex but neutral
                    relationship
                    between the feature and the target variable. That means that acceleration doesnt effect the outcome
                    of the model
                    in a significant way.</p></h6><br>
                    <img src="{% static 'mlpart/MpgDPAccelerationdata.jpeg' %}"/>
                </div>

                <div id="ModelY" class="tabcontent">
                    <h6><p>The following plot shows there is an approximately linear and positive trend between “Model Year”
                    and the
                    target variable, which means that a newer car will have lower fuel consumption than an old one.</p></h6><br>
                    <img src="{% static 'mlpart/MpgDPModelyeardata.jpeg' %}"/>
                </div>
            </div>
            <br>
        </div>
    </div>
    <br>

    <div class="container">
        <h5>
            <p>&rarr;Finally, we will focus on local Interpretability by randomly choosing a few observations. With the help of
            SHAP,
            we can generate explanations for a single prediction.
                The <i>SHAP Force plot</i> shows features that contribute to pushing the output from the base value (average model
            output) to the actual predicted value.
                <span style="color:red">Red color</span> indicates features that are pushing the prediction higher, and
                <span style="color:dodgerblue">blue color</span> indicates just the opposite.</p>
        </h5>
        <br>

        <div class="container" align="center">
            <div class="row justify-content-start">

                <div class="container">
                    <h4>&check;Explaining single prediction:</h4>
                    <br>
                    <div class="tab">
                        <button class="tablinks" onclick="openCity(event, '3')">Observation 3</button>
                        <button class="tablinks" onclick="openCity(event, '106')">Observation 106</button>
                        <button class="tablinks" onclick="openCity(event, '286')">Observation 286</button>
                        <button class="tablinks" onclick="openCity(event, '302')">Observation 302</button>
                    </div>
                    <br>
                </div>


                <div id="3" class="tabcontent">
                    <h6><p>The output value is the prediction for that observation. In this observation the output is 26.92
                    miles per gallon.
                    As we can see "Cylinders", "Weight", "Displacement" and "Horsepower" are the features driving to a
                    higher prediction
                    number, whereas "Model Year" and "Acceleration" drive the outcome to the left, affecting negatively
                    the outcome of the model.</p></h6><br>
                    <img src="{% static 'mlpart/MPG3FP.jpg' %}"/>
                </div>

                <div id="106" class="tabcontent">
                    <h6><p>The output value is the prediction for that observation. In this observation the output is 17.29
                    miles per gallon.
                    That is because the majority of the features ("Displacement","Weight","Horsepower" and "Cylinders")
                    drive the predicted
                    value to the left(lower mpg). Only the "model year" of the car is affecting positively.</p></h6><br>
                    <img src="{% static 'mlpart/MPG106FP.jpg' %}"/>
                </div>

                <div id="286" class="tabcontent">
                    <h6><p>The output value is the prediction for that observation. In this observation the output is 33.47
                    miles per gallon.
                    We got a high prediction because as we can see from the graph, 5 features are affecting positively
                    pushing the prediction
                    to the right, while only one feature("Horsepower) is affecting negatively.</p></h6><br>
                    <img src="{% static 'mlpart/MPG286FP.jpg' %}"/>
                </div>

                <div id="302" class="tabcontent">
                    <h6><p>The output value is the prediction for that observation. In this observation the output is 14.19
                    miles per gallon.
                    The predicted value is considered low because all 5 features that the model used, affected
                    negatively, pushing the prediction to the left.</p></h6><br>
                    <img src="{% static 'mlpart/MPG302FP.jpg' %}"/>
                </div>

                <br>
                <br>
                <br>


            </div>
            <br>


        </div>

    </div>


    <br>

</main>
<hr>
<footer style="padding: 5px 0px 5px!important" class="container">
    <p>© Varvarigos Georgios 2020-2021</p>
</footer>


<script>
    function openCity(evt, cityName) {
        var i, tabcontent, tablinks;
        tabcontent = document.getElementsByClassName("tabcontent");
        for (i = 0; i < tabcontent.length; i++) {
            tabcontent[i].style.display = "none";
        }
        tablinks = document.getElementsByClassName("tablinks");
        for (i = 0; i < tablinks.length; i++) {
            tablinks[i].className = tablinks[i].className.replace(" active", "");
        }
        document.getElementById(cityName).style.display = "block";
        evt.currentTarget.className += " active";
    }

    // Get the element with id="defaultOpen" and click on it
    document.getElementById("defaultOpen", "defaultOpen1").click();

</script>
</body>
</html>