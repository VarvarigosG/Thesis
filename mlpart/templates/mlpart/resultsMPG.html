<!DOCTYPE html>
<html lang="en">
<head>
    {% load static %}
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>GV AI EXPLAINABILITY</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
    <link rel="shortcut icon" href="{% static 'pages/Artificial-Intelligence-Trends.jpeg' %}"/>
    <style>
        .bs-example {
            margin: 20px;
        }

        .imgbox {
            display: grid;
            height: 100%;
        }

        .center-fit {
            max-width: 100%;
            max-height: 100vh;
            margin: auto;
        }
    </style>
</head>

<body>

<nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"></nav>

<main role="main">

    <div style="padding: 50px 0px 5px!important" class="jumbotron">
        <div class="container">
            <div class="row justify-content-start">

                <div class="col">
                    <h5 class="text-success display-4">The mpg score is {{scoreval}}
                        <input type="hidden" name="mpgVal" value={{scoreval}}>
                    </h5>
                </div>

                <div style="padding: 15px 0px 10px!important" class="d-flex justify-content-end">
                    <div class="col-md">
                        <h5>Want to make another diabetes prediction?</h5>
                        <p><a style="width: 390px !important;" class="btn btn-secondary text-info"
                              href="/mlpart/diabetes/" role="button">Go Ahead »</a></p>
                    </div>
                </div>

            </div>
        </div>
    </div>

    <div class="container">
        <h5>
            But you may be wondering, how did we come to that outcome? We used a Random Forest Regression model to make
            the
            prediction,
            and will use the fast TreeExplainer in SHAP to explain the model both globally and locally.
            This plots were made using the data(320 observations) that were used to train the model.
            <br><br>
            1)Firstly we will explain the entire dataset through the visualization of the importance of the features and
            their impact on the prediction.
        </h5>
        <br>

        <div class="container" align="center">
            <div class="row justify-content-start">

                <div class="container">
                    <h4> Explaining the entire dataset:</h4>
                    <div class="tab">
                        <button class="tablinks" onclick="openCity(event, 'Variable Importance Plot ')"
                                id="defaultOpen">Variable Importance Plot
                        </button>
                        <button class="tablinks" onclick="openCity(event, 'Summary Plot')">Summary Plot</button>
                    </div>
                </div>

                <div id="Variable Importance Plot " class="tabcontent">
                    The variable importance plot lists the most significant variables in descending order. The top
                    variables
                    contribute more to the model than the bottom ones and thus have high predictive power. So in this
                    case
                    "Displacement" and "Model Year" contribute more to the predicted outcome, when "Acceleration" does
                    not seem to
                    change
                    the choice of the model in any significant way.
                    <img src="{% static 'mlpart/MpgSPbarGlobaldata.jpeg' %}"/>
                </div>

                <div id="Summary Plot" class="tabcontent">
                    Another option to explain our model globally is the "Summary Plot" and it works as follows:
                    ->Feature importance: Variables are ranked in descending order.<br>
                    ->Impact: The horizontal location shows whether the effect of that value is associated with a higher
                    or lower prediction.<br>
                    ->Original value: Color shows whether that variable is high (in red) or low (in blue) for that
                    observation.<br>
                    ->Correlation: A high level of the “Model Year” content has a high and positive impact on the
                    prediction. The “high” comes from the red color,
                    and the “positive” impact is shown on the X-axis. Similarly, we will say the “Displacement” is
                    negatively
                    correlated with the target variable.
                    <img src="{% static 'mlpart/MpgSPGlobaldata.jpeg' %}"/>
                </div>

            </div>
            <br>


        </div>

    </div>


    <br>


    <div class="container">
        <h5>
            2)Secondly, we will focus on explaining single features by plotting the SHAP value of that feature vs. the
            value of the feature for all instances in the dataset. We will do that by plotting partial dependence plots.
            The partial dependence plot shows the marginal effect one or two features have on the predicted outcome of a
            machine learning model.The function automatically includes another variable that your chosen variable
            interacts most with.
        </h5>
        <br>

        <div class="container" align="center">
            <div class="row justify-content-start">

                <div class="container">
                    <h4> Explaining single feature:</h4>
                    <div class="tab">
                        <button class="tablinks" onclick="openCity(event, 'Cylinders')" id="defaultOpen1">
                            Cylinders
                        </button>
                        <button class="tablinks" onclick="openCity(event, 'Displacement')">Displacement</button>
                        <button class="tablinks" onclick="openCity(event, 'Horsepower')">Horsepower</button>
                        <button class="tablinks" onclick="openCity(event, 'Weight')">Weight</button>
                        <button class="tablinks" onclick="openCity(event, 'Acceleration')">Acceleration</button>
                        <button class="tablinks" onclick="openCity(event, 'ModelY')">Model Year</button>
                    </div>
                </div>

                <div id="Cylinders" class="tabcontent">
                    The plot below shows there exists an approximately linear but positive relationship between
                    “Pregnancies” and the target variable.
                    Also the interaction between "Pregnancies" and "Glucose" appears frequent
                    <img src="{% static 'mlpart/MpgDPCylindersdata.jpeg' %}"/>
                </div>

                <div id="Displacement" class="tabcontent">
                    The following plot shows there is an approximately linear and positive trend between “Glucose” and
                    the target variable,
                    and “Glucose” interacts with “BMI” frequently.
                    <img src="{% static 'mlpart/MpgDPDisplacementdata.jpeg' %}"/>
                </div>

                <div id="Horsepower" class="tabcontent">
                    The following plot shows there is a complex and somewhat negative trend between “Blood Pressure” and
                    the target variable,
                    and “Blood Pressure” interacts with “BMI” frequently.
                    <img src="{% static 'mlpart/MpgDPHorsepowerdata.jpeg' %}"/>
                </div>

                <div id="Weight" class="tabcontent">
                    The plot below shows there exists an approximately linear but neutral relationship between “Skin
                    Thickness” and the target variable,which
                    means that skin Thickness does not influence the prediction much.

                    <img src="{% static 'mlpart/MpgDPWeightdata.jpeg' %}"/>
                </div>

                <div id="Acceleration" class="tabcontent">
                    The plot below shows there exists an approximately linear but negative relationship between
                    “Insulin” and the target variable.
                    <img src="{% static 'mlpart/MpgDPAccelerationdata.jpeg' %}"/>
                </div>

                <div id="ModelY" class="tabcontent">
                    The following plot shows there is an approximately linear and positive trend between “BMI” and the
                    target variable,
                    and “BMI” interacts with “Glucose” frequently.
                    <img src="{% static 'mlpart/MpgDPModelyeardata.jpeg' %}"/>
                </div>

                <br>
                <br>
                <br>

            </div>
            <br>
        </div>
    </div>
    <br>

    <div class="container">
        <h5>
            3)Finally, we will focus on local Interpretability by randomly choosing a few observations. With the help of
            SHAP,
            we can generate explanations for a single prediction.<br><br>
            The SHAP plot shows features that contribute to pushing the output from the base value (average model
            output) to the actual predicted value.<br><br>
            Red color indicates features that are pushing the prediction higher, and blue color indicates just the
            opposite.
        </h5>
        <br>

        <div class="container" align="center">
            <div class="row justify-content-start">

                <div class="container">
                    <h4> Explaining single prediction:</h4>
                    <div class="tab">
                        <button class="tablinks" onclick="openCity(event, '3')">3</button>
                        <button class="tablinks" onclick="openCity(event, '106')">106</button>
                        <button class="tablinks" onclick="openCity(event, '286')">286</button>
                        <button class="tablinks" onclick="openCity(event, '302')">302</button>
                    </div>
                </div>


                <div id="3" class="tabcontent">
                    The output value is the prediction for that observation. In this observation the output is 26.92 miles per gallon.
                    As we can see "Cylinders", "Weight", "Displacement" and "Horsepower" are the features driving to a higher prediction
                    number, whereas "Model Year" and "Acceleration" drive the outcome to the left, affecting negatively the outcome of the model
                    <img src="{% static 'mlpart/MPG3FP.jpg' %}"/>
                </div>

                <div id="106" class="tabcontent">
                    The output value is the prediction for that observation. In this observation the output is 17.29 miles per gallon.
                    That is because the majority of the features ("Displacement","Weight","Horsepower" and "Cylinders") drive the predicted
                    value to the left(lower mpg). Only the "model year" of the car is affecting positively.
                    <img src="{% static 'mlpart/MPG106FP.jpg' %}"/>
                </div>

                <div id="286" class="tabcontent">
                    The output value is the prediction for that observation. In this observation the output is 33.47 miles per gallon.
                    We got a high prediction because as we can see from the graph, 5 features are affecting positively pushing the prediction
                    to the right, while only one feature("Horsepower) is affecting negatively.
                    <img src="{% static 'mlpart/MPG286FP.jpg' %}"/>
                </div>

                <div id="302" class="tabcontent">
                    The output value is the prediction for that observation. In this observation the output is 14.19 miles per gallon.
                    The predicted value is considered low because all 5 features that the model used, affected
                    negatively, pushing the prediction to the left.
                    <img src="{% static 'mlpart/MPG302FP.jpg' %}"/>
                </div>

                <br>
                <br>
                <br>


            </div>
            <br>


        </div>

    </div>


    <br>

</main>
<hr>
<footer style="padding: 5px 0px 5px!important" class="container">
    <p>© Varvarigos Georgios 2020-2021</p>
</footer>


<script>
    function openCity(evt, cityName) {
        var i, tabcontent, tablinks;
        tabcontent = document.getElementsByClassName("tabcontent");
        for (i = 0; i < tabcontent.length; i++) {
            tabcontent[i].style.display = "none";
        }
        tablinks = document.getElementsByClassName("tablinks");
        for (i = 0; i < tablinks.length; i++) {
            tablinks[i].className = tablinks[i].className.replace(" active", "");
        }
        document.getElementById(cityName).style.display = "block";
        evt.currentTarget.className += " active";
    }

    // Get the element with id="defaultOpen" and click on it
    document.getElementById("defaultOpen", "defaultOpen1").click();

</script>
</body>
</html>