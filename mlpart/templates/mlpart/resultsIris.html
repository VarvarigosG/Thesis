<!DOCTYPE html>
<html lang="en">
<head>
    {% load static %}
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>GV AI EXPLAINABILITY</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
    <link rel="shortcut icon" href="{% static 'pages/Artificial-Intelligence-Trends.jpeg' %}"/>
    <style>
        .bs-example {
            margin: 20px;
        }

        .imgbox {
            display: grid;
            height: 100%;
        }

        .center-fit {
            max-width: 100%;
            max-height: 100vh;
            margin: auto;
        }
    </style>
</head>

<body>

<nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark"></nav>

<main role="main">

    <div style="padding: 50px 0px 5px!important" class="jumbotron">
        <div class="container">
            <div class="row justify-content-start">

                <div class="col">
                    {% if messages %}
                    <ul class="messages">
                        {% for message in messages %}
                        <h5 class="text-success display-4" {% if message.tags %} class="{ message.tags }}" {% endif %}>
                       <i> {{message}}</i>
                        </h5>

                        {% endfor %}
                    </ul>
                    {% endif %}
                </div>

                <div style="padding: 15px 0px 10px!important" class="d-flex justify-content-end">
                    <div class="col-md">
                        <h5>Want to make another Iris species prediction?</h5>
                        <p><a style="width: 390px !important;" class="btn btn-secondary text-info"
                              href="/mlpart/iris/" role="button">Go Ahead »</a></p>
                    </div>
                </div>

            </div>
        </div>
    </div>

    <div class="container">
        <h5>
            <p>But you may be wondering, how did we come to that outcome? We used a k-nearest neighbors algorithm(k-NN)
            model to make the
            prediction,that was trained
                with the following dataset : <a href="https://archive.ics.uci.edu/ml/datasets/iris">Iris Data Set</a>.
            To explain the model both globally and locally, we will use the KernelExplainer in SHAP.
            The plots were made using the data(120 observations) that were used to train the model.
            </p><br><br>
            <p>&rarr;Firstly we will explain the entire dataset through the visualization of the importance of the features and
            their impact on the prediction.For that we will use the <i>'Variance Importance'</i> and <i>'Summary' plots</i>.</p>
        </h5>
        <br>

        <div class="container" align="center">
            <div class="row justify-content-start">

                <div class="container">
                    <h4>&check;Explaining the entire dataset:</h4>
                    <br>
                    <div class="tab">
                        <button class="tablinks" onclick="openCity(event, 'Variable Importance Plot')"
                                id="defaultOpen">Variable Importance Plot
                        </button>
                        <button class="tablinks" onclick="openCity(event, 'Summary Plot')">Summary Plot</button>
                    </div>
                    <br>
                </div>

                <div id="Variable Importance Plot" class="tabcontent">
                    <h6><p>The variable importance plot lists the most significant variables in descending order. The top
                    variables
                    contribute more to the model than the bottom ones and thus have high predictive power. So in this
                    case
                    "Petal Length" and "Petal Width" contribute more to the predicted outcome when "Sepal Length" and
                    "Sepal Width" do not seem to affect the choice of the model in a major way.</p></h6>
                    <img src="{% static 'mlpart/IrisSPbarGlobal.jpeg' %}"/>
                </div>

                <div id="Summary Plot" class="tabcontent">
                    <h6><p>Another option to explain our model globally is the "Summary Plot" and it works as follows:<br>
                    &rarr;Feature importance: Variables are ranked in descending order.<br>
                    &rarr;Impact: The horizontal location shows whether the effect of that value is associated with a higher
                    or lower prediction.<br>
                    &rarr;Original value: Color shows whether that variable is high (in red) or low (in blue) for that
                    observation.<br>
                    &rarr;Correlation: A high level of the "Petal Length" content has a high and positive impact on the
                    prediction. The “high” comes from the red color and the “positive” impact is shown on the X-axis.</p></h6>
                    <img src="{% static 'mlpart/IrisSPGlobal.jpeg' %}"/>
                </div>
            </div>
            <br>
        </div>
    </div>
    <br>

    <div class="container">
        <h5>
            <p>&rarr;Secondly, we will focus on explaining single features by plotting the SHAP value of that feature vs. the
            value of the feature for all instances in the dataset. We will do that by plotting <i>Partial Dependence Plots</i>.
            The partial dependence plot shows the marginal effect one or two features have on the predicted outcome of a
            machine learning model.The function automatically includes another variable that your chosen variable
                interacts most with.</p>
        </h5>
        <br>

        <div class="container" align="center">
            <div class="row justify-content-start">

                <div class="container">
                    <h4>&check;Explaining single feature:</h4>
                    <br>
                    <div class="tab">
                        <button class="tablinks" onclick="openCity(event, 'PetalL')">Petal Length</button>
                        <button class="tablinks" onclick="openCity(event, 'PetalW')">Petal Width</button>
                        <button class="tablinks" onclick="openCity(event, 'SepalL')">Sepal Length</button>
                        <button class="tablinks" onclick="openCity(event, 'SepalW')">Sepal Width</button>
                    </div>
                    <br>
                </div>

                <div id="PetalL" class="tabcontent">
                    <h6><p>
                        The plot below shows there exists a linear but positive relationship between
                        “Petal Length” and the target variable. Specifically we can spot some kind of neighbourhoods,
                        that based on the "Petal Length" input of the user, classify the iris species differently.
                    </p></h6><br>
                    <img src="{% static 'mlpart/IrisDPPetalLdata.jpeg' %}"/>
                </div>

                <div id="PetalW" class="tabcontent">
                    <h6><p>
                        The following plot shows there is a linear and positive trend between “Petal Width” and
                        the target variable. Specifically we can spot some kind of neighbourhoods, that based on the
                        "Petal Width" input of the user, classify the iris species differently.</p></h6><br>
                    <img src="{% static 'mlpart/IrisDPPetalWdata.jpeg' %}"/>
                </div>

                <div id="SepalL" class="tabcontent">
                    <h6><p>
                        The following plot shows there is a linear and neutral relationship between “Sepal Length” and
                        the target variable. That shows us that "Sepal Length" does not influence the model output, except in
                        some specific input values(e.g 6.7 cm) when combined with a specific "Petal Width" value.
                    </p></h6><br>
                    <img src="{% static 'mlpart/IrisDPSepalLdata.jpeg' %}"/>
                </div>

                <div id="SepalW" class="tabcontent">
                    <h6><p>
                        The following plot shows there is a linear and neutral relationship between “Sepal Width” and
                        the target variable. That shows us that "Sepal Width" does not influence the model output, except in
                        some specific input values(e.g 2.55 cm) when combined with a specific "Petal Length" value.
                    </p></h6><br>
                    <img src="{% static 'mlpart/IrisDPSepalWdata.jpeg' %}"/>
                </div>

            </div>
            <br>
        </div>
    </div>
    <br>


    <div class="container">
        <h5>
            <p>&rarr;Finally, we will focus on local Interpretability by randomly choosing a few observations. With the help of
            SHAP,
            we can generate explanations for a single prediction.
            The <i>SHAP Force plot</i> shows features that contribute to pushing the output from the base value (average model
            output) to the actual predicted value.
            <span style="color:red">Red color</span> indicates features that are pushing the prediction higher,
                and <span style="color:dodgerblue">blue color</span> indicates just the opposite.</p>
        </h5>
        <br>

        <div class="container" align="center">
            <div class="row justify-content-start">

                <div class="container">
                    <h4>&check;Explaining single prediction:</h4>
                    <br>
                    <div class="tab">
                        <button class="tablinks" onclick="openCity(event, '8')">8</button>
                        <button class="tablinks" onclick="openCity(event, '35')">35</button>
                        <button class="tablinks" onclick="openCity(event, '75')">75</button>
                        <button class="tablinks" onclick="openCity(event, '103')">103</button>
                    </div>
                    <br>
                </div>


                <div id="8" class="tabcontent">
                    <h6><p>The output value is the prediction for that observation. As we can see "Petal Length"(4.5 cm)
                        was the feature that determined the outcome of the prediction model by pushing the prediction to
                        the left.</p></h6><br>
                    <img src="{% static 'mlpart/IrisFP8.jpg' %}"/>
                </div>

                <div id="35" class="tabcontent">
                    <h6><p>The output value is the prediction for that observation.
                    As we can see here "Petal Length"(4.5 cm),"Petal Width"(2.3cm) and "Sepal Width"(2.6cm) were the features that
                    determined the outcome of the prediction model by pushing the prediction to the left.</p></h6><br>
                    <img src="{% static 'mlpart/IrisFP35.jpg' %}"/>
                </div>

                <div id="75" class="tabcontent">
                    <h6><p>The output value is the prediction for that observation.
                    This observation differs from the previous ones because the small value of the feature "Petal Length"(1.3cm)
                    is what made the prediction to move to the right.</p></h6><br>
                    <img src="{% static 'mlpart/IrisFP75.jpg' %}"/>
                </div>

                <div id="103" class="tabcontent">
                    <h6><p>The output value is the prediction for that observation.
                    This observation is very similar to the previous one because the small value of the feature "Petal Length"(1.6cm)
                    is what made the prediction to move to the right again.</p></h6><br>
                    <img src="{% static 'mlpart/IrisFP103.jpg' %}"/>
                </div>
            </div>
            <br>
        </div>
    </div>
    <br>
</main>
<hr>
<footer style="padding: 5px 0px 5px!important" class="container">
    <p>© Varvarigos Georgios 2020-2021</p>
</footer>


<script>
    function openCity(evt, cityName) {
        var i, tabcontent, tablinks;
        tabcontent = document.getElementsByClassName("tabcontent");
        for (i = 0; i < tabcontent.length; i++) {
            tabcontent[i].style.display = "none";
        }
        tablinks = document.getElementsByClassName("tablinks");
        for (i = 0; i < tablinks.length; i++) {
            tablinks[i].className = tablinks[i].className.replace(" active", "");
        }
        document.getElementById(cityName).style.display = "block";
        evt.currentTarget.className += " active";
    }

    // Get the element with id="defaultOpen" and click on it
    document.getElementById("defaultOpen").click();
</script>
</body>
</html>